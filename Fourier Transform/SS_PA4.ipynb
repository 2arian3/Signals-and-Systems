{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def spectral_fourier_transform(data, samples=2048):\n",
    "    result = []\n",
    "    for i in range(data.shape[0] // samples + 1):\n",
    "        start, end = i * samples, (i+1) * samples\n",
    "        if end > data.shape[-1]:\n",
    "            break\n",
    "        result.append(np.fft.fft(data[start:end]))\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def filtering(freq, interval=(100, 5000)):\n",
    "    legal_freq = freq[(freq >= interval[0]) & (freq <= interval[1])]\n",
    "    return np.where(freq == legal_freq[0])[0][0], np.where(freq == legal_freq[-1])[0][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def noiseprint(transform, rate, interval=(100, 5000), samples=2048, points_per_slice=6):\n",
    "    result = []\n",
    "    freq = np.fft.fftfreq(samples, d=1/rate)\n",
    "    starting_frequency, ending_frequency = filtering(freq, interval)\n",
    "    slice_space = (interval[1] - interval[0]) / points_per_slice\n",
    "    sorted_freq = np.sort(freq[starting_frequency:ending_frequency+1])\n",
    "\n",
    "    for time_slice in transform:\n",
    "        max_freq = []\n",
    "        window_start = starting_frequency\n",
    "        freq_to_fourier_transform = dict()\n",
    "\n",
    "        for i in range(starting_frequency, ending_frequency+1):\n",
    "            freq_to_fourier_transform[freq[i]] = time_slice[i]\n",
    "\n",
    "        for _ in range(points_per_slice):\n",
    "            window_end = window_start\n",
    "            while window_end < sorted_freq.shape[-1] and sorted_freq[window_end] <= slice_space + sorted_freq[window_start]:\n",
    "                window_end += 1\n",
    "            maximum_fourier_transform = max(np.absolute([freq_to_fourier_transform[sorted_freq[i]] for i in range(window_start, window_end)]))\n",
    "            for frequency in sorted_freq[window_start:window_end]:\n",
    "                if maximum_fourier_transform == np.absolute(freq_to_fourier_transform[frequency]):\n",
    "                    max_freq.append(frequency)\n",
    "                    break\n",
    "            window_start = window_end + 1\n",
    "        result.append(max_freq)\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def similarity(song_spec, clip_spec, points_per_slice=6):    \n",
    "    song_flat = song_spec.flatten()\n",
    "    clip_flat = clip_spec.flatten()\n",
    "    \n",
    "    sim_window_size = points_per_slice - 1\n",
    "    score = 0\n",
    "    for anchor in range(clip_flat.shape[0] - points_per_slice):\n",
    "        anchor_y = anchor % points_per_slice\n",
    "        sim_window = clip_flat[anchor: anchor+sim_window_size]\n",
    "        for song_anchor in range(anchor_y, song_flat.shape[0] - points_per_slice - 1, points_per_slice):\n",
    "            if clip_flat[anchor] == song_flat[song_anchor]:\n",
    "                if np.count_nonzero((song_flat[song_anchor:song_anchor+sim_window_size] - sim_window) == 0) >= 4:\n",
    "                    score += 1\n",
    "    \n",
    "    score /= song_flat.shape[0]\n",
    "    return score\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "database = dict()\n",
    "\n",
    "print('Creating Database ...')\n",
    "for root, _, files in os.walk('data'):\n",
    "    for wave in files:\n",
    "        rate, data = wavfile.read(root + '/' + wave)\n",
    "        fourier_transform = spectral_fourier_transform(data)\n",
    "        database[wave] = noiseprint(fourier_transform, rate)\n",
    "print('Created Database Successfully ...')\n",
    "\n",
    "print('Reading Inputs ...')\n",
    "for root, _, files in os.walk('clip'):\n",
    "    for wave in files:\n",
    "        rate, data = wavfile.read(root + '/' + wave)\n",
    "        fourier_transform = spectral_fourier_transform(data)\n",
    "        input_noiseprint = noiseprint(fourier_transform, rate)\n",
    "        result = ('', -1000)\n",
    "        for database_wave, wave_noiseprint in database.items():\n",
    "            s = similarity(np.array(wave_noiseprint), np.array(input_noiseprint))\n",
    "            if result[1] < s:\n",
    "                result = (database_wave, s)\n",
    "        print('{} is similar to {}'.format(wave, result[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating Database ...\n",
      "Created Database Successfully ...\n",
      "Reading Inputs ...\n",
      "clip1.wav is similar to 4_el_bimbo.wav\n",
      "clip3.wav is similar to 1_prelude.wav\n",
      "clip2.wav is similar to 3_chanson_du_toreador.wav\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}